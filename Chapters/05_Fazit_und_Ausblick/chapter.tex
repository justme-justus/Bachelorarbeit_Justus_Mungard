\chapter{Schlussbetrachtung} \label{Fazit und Ausblick}
\section{Fazit}

In dieser Arbeit konnte erfolgreich demonstriert werden, dass eine sichere und isolierte Hybrid Cloud-Vernetzung ohne den Einsatz von proprietären Herstellerlösungen möglich ist. Robuste und offen dokumentierte Technologien wie \gls{IPsec}, \gls{DNS} oder \gls{BGP}, welche im Internet schon seit Jahrzehnten genutzt werden, haben auch in \glqq modernen\grqq{} Cloud-Umgebungen weiterhin ihre Berechtigung.\\
Im Allgemeinen konnten die Vorerfahrungen des Autors aus dem \textit{klassischen} Netzwerkbereich gewinnbringend genutzt werden, um sie auf Ideen und Technologien des (hybriden) Cloud-Networkings zu übertragen: Am Ende des Tages werden auch in dieser Disziplin Pakete von A nach B verschickt und Cloud-Ingenieure der \textit{Big Player} AWS und Azure setzen in großen Teilen auf bewährte Technologien.\\
Es reicht aber auch nicht, sich ausschließlich auf das vorhandene Skill-Set zu berufen. Es haben eben nicht mehr alle Paradigmen aus der \glqq alten Welt\grqq{} ihre Gültigkeit: Technologien kamen dazu, zum Teil wurden alte Zöpfe abgeschnitten. So sind \glslink{OSI-Schichtenmodell}{OSI-Schichten} 1 und 2 für den Netzwerk-Administrator in der Cloud gewissermaßen nicht existent und spielen keine Rolle mehr. Im Gegenzug muss dieser sich jedoch mit neuen Werkzeugen beschäftigen. Das hier genutzte Automatisierungswerkzeug Terraform ist nur eines unter vielen.\\
Silodenken, bei dem Netzwerk, Security, Datenbanken, etc. in Einzeldisziplinen aufgeteilt werden, ist in der Cloud nicht mehr zeitgemäß, da diese Komponenten noch viel enger vermascht sind. Beim Einsatz von Werkzeugen wie Terraform muss man sich zwangsläufig mit verschiedensten Aspekten der Cloud beschäftigen.\\
Auch die Entkoppelung von der \glqq wahren\grqq{}, physischen Infrastruktur und die dadurch unterstützte Annahme, dass durch eine \glqq Cloud-Magie\grqq{} alles problemlos und für alle Ewigkeiten funktioniert, kann sich als zu fahrlässig herausstellen. So kann (und will) man gar nicht mehr wissen, \glqq welches Bit über welchen Draht im Rechenzentrum läuft\grqq{}, aber eine gute technische Ressourcenplanung und das Durchdenken von \gls{Fallback}-Szenarien sind nach wie vor unentbehrliche Prozesse. Dies hat der Brand im Straßburger Rechenzentrum des Cloud-Providers OVH nochmals deutlich vor Augen geführt\cite{ChristofKerkmann2021}.\\
Mit Use Case 1 konnte demonstriert werden, wie ein verteilter Internetdienst über Cloud-Grenzen hinweg existieren und dadurch redundant ausgelegt werden kann. Ein Re-Routing von Paketen erfolgt, falls eine Verbindung zwischen Cloud-Standorten wegfällt. Es lassen sich dabei noch weitere \gls{VPN}-Verbindungen zu Gegenstellen bereitstellen, um die Redundanz und Bandbreite nochmals zu erhöhen (s. Kapitel \ref{ausblick}).\\
In Use Case 2 konnte erfolgreich gezeigt werden, wie geobasiertes \gls{DNS} genutzt werden kann, um Verbindungen mit niedrigen Latenzen zu gewährleisten. Außerdem ist es möglich, Infrastruktur neu zu provisionieren und daraufhin direkt per \gls{DNS} erreichbar zu machen.\\ 
Die in der Arbeit aufgezeigten Use Cases können mit Hilfe von Terraform und \gls{IPAM} automatisiert ausgerollt und wieder zurückgebaut werden. In der Praxis, bei der bei Kunden keine \glqq grüne Wiese\grqq{} vorherrscht, kann u.U. nicht auf diese Tools zurückgegriffen und es muss im Einzelfall betrachtet werden, welche Schnittstellen und Werkzeuge bereits genutzt werden bzw. sinnvoll erscheinen.\\
Grundlegend lässt sich sagen, dass sich viele Themen mit Fokus Cloud in irgendeiner Form automatisieren lassen. Public Clouds sind grob umschrieben große \glqq Baukasten-Systeme\grqq{} mit diversen Kombinationsmöglichkeiten und es spielen die eigentlichen Tools nur eine untergeordnete Rolle: Wichtig ist im Sinne des Kunden eine Kostensenkung durch fehlerarme und optimierte Prozesse. Bevor Prozesse aber automatisiert abgebildet werden können, bedürfen sie einer genauen Erfassung mit gleichzeitiger Formulierung von messbaren (Kosten-)Kriterien.\\
Sollte eine Hybrid Cloud-Strategie in Erwägung gezogen werden, muss man sich bewusst sein, dass man technologisch oftmals nach einem gemeinsamen Nenner sucht. Dieses Ausarbeitung war insofern eine dankbare Aufgabe, als dass die Public Cloud-Provider AWS und Azure offene Technologien für \gls{VPN} und Routing anbieten. Würde jedoch nur eine Plattform bspw. keine \gls{BGP}-Unterstützung haben, wäre der gemeinsame Nenner ein anderer: Änderungen der Topologie oder ein kompletter Verzicht auf dynamisches Routing hätten in Betracht gezogen werden müssen. Kleinere aber lösbare Probleme offenbarten sich bereits bei der Auswahl des richtigen Transfernetzes für das \gls{BGP}-Peering (s. Kapitel \ref{transfer-azure-aws}) oder der Auswahl des \gls{VPN-Konzentrator}s für \gls{Roadwarrior}-\gls{VPN} (s. Kapitel \ref{uc1-vorauswahl}).\\
Hersteller von \gls{SD-WAN}-Lösungen versuchen diese Probleme zu umgehen, indem mehr oder weniger \textbf{alle} Netzwerk-Logiken in virtuelle Maschinen ausgelagert werden. Nachteile wurden mit Vendor Lock-In und somit fehlender Interoperabilität bereits genannt. Weiterhin ist die grundlegende Annahme, dass alles so bleibt wie zum Zeitpunkt des \gls{Deployment}s. Jedoch ist Cloud technologisch ein \textit{moving target}: APIs oder notwendige Technologien können sich jederzeit ändern oder abgekündigt werden\cite{Yegge2020}. Gehen Hersteller dann schnellstmöglich auf Änderungen bei den Cloud-Providern ein? Können Bugfixes dann problemlos eingespielt werden, ohne die Produktion zu gefährden?\\ 
Die Gefahr, dadurch einen \textit{Single-Point-Of-Failure} ins Netzwerk zu integrieren, ist hoch, v.a. wenn man bedenkt, dass vergleichbare Lösungen ohne den Einsatz von \glqq Proxies\grqq{} und mit direkter Unterstützung der Cloud-Provider möglich sind, wie diese Arbeit zeigen konnte.

\section{Ausblick}\label{ausblick}
Wie bereits in der Abgrenzung geschrieben, sollte in dieser Arbeit wenig auf (mögliche) Bandbreiten eingegangen werden, da diese von zu vielen Faktoren beeinflusst werden kann:
\begin{itemize}
    \item Sind die virtuellen Maschinen und \gls{VPN-Gateway}s performant genug, um die verfügbaren Bandbreiten auszunutzen?
    \item Sind die Verschlüsselungsparameter der Tunnel optimal gewählt?
    \item Unterscheiden sich Bandbreiten zwischen verschiedenen Protokollen (\gls{UDP} \textit{versus} \gls{TCP} bspw.) eklatant?
    \item Ermöglichen Cloud-Plattformen Optimierungen wie z.B. \gls{TCP}-Offloading?
    \item Wird auf einer Verbindung fragmentiert? Wie wirken sich verschiedene \gls{MTU}-Parameter aus?
    \item Sind die Cloud-Standorte (Dublin und Frankfurt) Routing-technisch zu weit voneinander entfernt?
    \item Wie kann sich Equal Cost Multipath (ECMP) auf die verfügbare Bandbreite auswirken? Funktioniert ECMP richtungsunabhängig?
\end{itemize}
Grundsätzlich hat sich im Laufe dieser Arbeit gezeigt, dass die Verbindungen, auch durch die zusätzliche Redundanz des Backbones, stabil sind. Weiterhin war in Anbetracht typischer Anforderungen im Firmenumfeld die Performance gut, z.B. wenn über den Tunnel auf entfernten Systemen per \gls{SSH} gearbeitet wurde oder beim Abruf von Inhalten des internen Webservers. Wie vereinzelte Messungen jedoch zeigen, existiert zwischen AWS und Azure wahrscheinlich ein Flaschenhals (s. Listing \ref{iperf3-vpc-vnet}). Hohe Paketverluste, die dies rechtfertigen würden, sind nicht zu messen (s. Listing \ref{floodping}).\\
Um genauere Aussagen diesbezüglich treffen zu können, wäre eine weitere Ausarbeitung vorstellbar. Dort könnte z.B. nach Definition von Performance-Kriterien typischer Anwendungen untersucht werden, wie sich Variationen in oben genannten Punkten auf Bandbreiten auswirken. Jitter, Latenz und Paketverlust wären weitere Parameter, die man untersuchen könnte. Als Basiswert wären bspw. Service-Level-Agreements von AWS und Azure heranzuziehen.\\
Es könnten geeignete Tools entwickelt werden, um Standorte dauerhaft zu messen und ggf. temporär aus einer Topologie herauszunehmen, sollten Kriterien nicht mehr erfüllbar sein. Durch geeignete Automatisierungsmechanismen müssten verbliebene User auf andere Standorte \glqq umgelenkt\grqq{} werden.\\
Es wurde in der Abgrenzung angedeutet, dass diese Arbeit Use Cases für kleine bis mittelgroße Skalierungen herausstellen wird. Während die in dieser Arbeit verwendeten \gls{VPN-Gateway}s der Public Cloud-Provider \textit{bis zu} 1,25 Gbit/s Bandbreite (pro \gls{VPN}-Verbindung) zusichern, sind es bei AWS Direct Connect \cite{awsdc2020} und Azure ExpressRoute \cite{Washam2014} bis zu 100 Gbit/s. Dies sind dedizierte Schicht 2-Verbindungen vom eigenen Rechenzentrum bis zum Rechenzentrum eines Public Cloud-Providers.\\
Diese Verbindungen sind in der Theorie ausfallsicherer, da die Pakete zwischen den Standorten nicht über das Internet geroutet, sondern mit der Unterstützung des Internet Service Providers direkt zwischen den Rechenzentren auf Schicht 2 \textit{gebridget} werden. Außerdem lassen sich hier Services wie Bidirectional Forwarding Detection (BFD) nutzen, um deutlich schnellere \gls{BGP}-Konvergenzzeiten als in dieser Arbeit (vgl. \ref{tf-base-deployment-ping-ok-missing-link}) zu erreichen\cite{azurebfd2018}.
An dieser Stelle könnte angesetzt werden, um mit einer weiteren Arbeit zu untersuchen, inwiefern ein Hybrid Cloud-Setup mit AWS Direct Connect bzw. Azure ExpressRoute automatisiert konfiguriert werden könnte. Auch eine Kombination aus \gls{VPN}, Direct Connect und ExpressRoute wäre vorstellbar. Folgende Fragestellungen sind dann zu untersuchen:
\begin{itemize}
    \item Ließe sich ein \textit{Backbone} ausschließlich per AWS Direct Connect und Azure ExpressRoute analog zu dieser Arbeit aufbauen?
    \item Ist es möglich, direkt zwischen AWS und Azure zu bridgen?
    \item Wie sind mögliche Ausfallszenarien? Wäre ein Re-Routing über einen anderen Pfad ebenso gegeben, wenn eine Leitung ausfällt?
    \item Ist ein Mischbetrieb mit \gls{VPN} (\gls{IPsec}), Direct Connect und ExpressRoute möglich bzw. sinnvoll? Funktioniert dann noch dynamisches Routing (BGP)?
\end{itemize}
DNS war in dieser Arbeit das zentrale Protokoll, um \gls{Roadwarrior} mit Hilfe von \gls{GeoIP} zum nächstgelegen Standort zu lenken. Die Grundannahme war dabei, dass der \gls{DNS}-Resolver in der Nähe des \gls{Roadwarrior}s installiert ist, da lediglich die (letzte) Resolver-IP beim autoritativen Nameserver sichtbar ist (siehe \ref{dns-resolver-region}). Es existiert seit 2016 ein \textit{Informational \gls{RFC}}, welcher dieses Problem mit der \textit{EDNS}-Option \textit{\gls{Client} Subnet} zu lösen versucht\cite{rfc7871}. Diese könnte zukünftig hilfreich sein, um den ursprünglichen Standort nach einer Kaskadierung von \gls{DNS}-Anfragen oder \gls{NAT} zu erhalten. Die Option wurde in der Arbeit nicht berücksichtigt, da eine breite Unterstützung von typischen \gls{DNS}-Resolvern zum Zeitpunkt der Arbeit noch nicht gegeben war.\\ 
Cloud Computing offenbart viele Felder, in denen weitere Ausarbeitungen denkbar sind und es ist auch beruflich ein immer wichtiger werdendes Themenfeld:
Eine Umfrage unter IT-Freelancern aus dem Jahr 2021 zeigt, dass nach ihrem Verständnis die Themen Automatisierung, Cloud Computing und Security die größten Chancen haben, trotz Corona-Krise projektiert zu werden\cite{SOLCOMGmbH2021}. Alle drei Themen wurden \glqq naturgemäß\grqq{} bis zu einem gewissen Grad in dieser Arbeit behandelt und es zeigt noch mal deutlich, dass thematische Überlagerungen zukünftig kaum noch zu verhindern und eher als gegenseitige Antreiber zu verstehen sind.

\iffalse
% Dabei besitzt die Azure-\gls{VM} nur einen CPU-Kern. Es wurden meist kleine Maschinentypen gewählt:

%\begin{minted}[breaklines,frame=single]{bash}
%root@vyos-azure-ovpn-gw:~# grep -E 'processor|model name' < /proc/cpuinfo
%processor       : 0
%model name      : Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz
%\end{minted}

Natürlich halten solche \textit{subjektiven} Aussagen keiner wissenschaftlichen Auseinandersetzung stand und eine weitere Ausarbeitung wäre notwendig. Dort könnte z.B. nach Definition von Performancekriterien typischer Anwendungen untersucht werden, wie sich Variationen in vorher genannten Punkten auf Bandbreiten auswirken. Jitter, Latenz und Paketverlust wären weitere Parameter, die man untersuchen könnte. Weiterhin könnte untersucht werden, wie geeignete Tools entwickelt werden können, um Standorte dauerhaft zu messen und ggf. herunterzufahren, sollten Kriterien nicht erfüllbar sein

Performancekriterien typischer Anwendungen mit $n$ Benutzern definiert und daraufhin untersucht, wie Variationen in den vorher genannten Punkten zu einer Verbesserung bzw. Verschlechterung führen.
%ECMP / Redundanz

und es wird auf die SLAs von AWS und Microsoft zu den Themen verwiesen.
Es gibt viele weitere Guides... für Härtung und Bandbreiten MTU usw... eigene BA
%Monitoring pro Cloud-Standort -> im Zweifel abreißen mit Terraform
%Keine Bandbreiten gemessen in Use-Case 1 und 2: Dafür zu viele Variablen: eigener Standort, Hardware etc. -> Verweis auf SLAs, iperf3
%BFD

Härtungsmaßnahmen und wie sich Parameter optimieren lassen
Bandbreitenmessungen oder Benchmarking einiger typischer Anwendungen, evtl. mit Benutzerumfragen...
Wie ließe sich das Ganze mit Direct Connect / ExpressRoute umsetzen?
BYOIP
\fi
