\chapter{Einleitung}

Die NetUSE AG ist ein IT-Dienstleister aus Kiel mit den Schwerpunkten Infrastruktur, Security und Netzwerk. Viele Kunden der NetUSE AG nehmen zunehmend \textit{Public Cloud}-basierte Dienste in Anspruch, um zuvor hausinterne oder bei externen Dienstleistern wie der NetUSE AG gehostete IT-Infrastruktur zu verlagern oder zu erweitern. Die Kunden der NetUSE AG sehen in der Cloud Möglichkeiten für Kosteneinsparungen, vereinfachter Skalierbarkeit und einer hohen Verfügbarkeit.\\
Die NetUSE AG unterstützt ihre Kunden bei der Migration in die Cloud. Hier stehen zwei Public Cloud-Anbieter im Fokus: Amazon Web Services (AWS) und Microsoft Azure (Azure). Weiterhin unterstützt die Firma Kunden beim Aufbau einer \textit{Private Cloud}, bei der Rechenressourcen exklusiv für einen Mandanten zur Verfügung stehen. Für Private Clouds setzt die NetUSE AG auf Red Hat OpenShift.\\
In klassischen \gls{on-premises} IT-Diensten erstreckt sich der Aufbau und Betrieb über mehrere Teams. Für den Aufbau eines einzelnen IT-Dienstes sind bei der NetUSE AG folgende Teams beteiligt: Server-Einbau und -Installation (Team \glqq{Infrastruktur}\grqq{}), Netzwerkanbindung (Team \glqq{Netzwerk}\grqq{}), Pflege von Firewall-Regeln (Team \glqq{Security}\grqq{}).\\
In der Cloud entfallen diese Arbeitschritte meist durch Automatisierung und Self Service, so dass per Knopfdruck (virtuelle) Maschinen und Infrastruktur bereitgestellt werden können\cite{Karlstetter2017a}. Dies passiert in größeren Skalierungen automatisiert, z.B. Skript-gesteuert oder mit Hilfe von Automatisierungs-Frameworks wie Ansible oder Terraform. Hierfür stellen Cloud-Plattformen Schnittstellen zur Verfügung\cite{edelman2018}\cite{Brikman2019}. Typische IT-Prozesse wie die Grundinstallation eines Betriebssystems entfallen.\\
In der Public Cloud existiert keine klassische Netzwerk-Infrastruktur mehr, welche ehemals für einen Rechenzentrumsbetrieb gebraucht wurde: Broadcast-fähige Schicht-2-Domänen zur Findung lokaler Netzwerkteilnehmer (ARP [IPv4] bzw. Neighbor Discovery [IPv6]) werden nicht mehr benötigt. Die Cloud \textit{kennt} naturgemäß alle Teilnehmer und es ist nach Belieben möglich, Konnektivität zwischen diesen zu ermöglichen. Netzwerke in der Cloud sind Software-Defined (SDN)\cite{Seidel2015}. Das hat zur Folge, dass gewohnte Werkzeuge eines Netzwerk-Ingenieurs wegfallen, während gleichzeitig neue dazu gekommen sind.

\section{Ziel}

Es existieren bereits proprietäre Lösungen am Markt, um eine Vernetzung über Cloud-Anbieter hinweg zu ermöglichen. Sie fallen in die Kategorie \textit{Software-Defined Wide Area Network (SD-WAN)} und sind nicht interoperabel zu SD-WAN-Lösungen anderer Hersteller.\\
Ziel der Arbeit ist es, ein möglichst herstellerunabhängiges Netzwerk, welches eine Ende-zu-Ende-Konnektivität ermöglicht, zwischen verschiedenen Cloud-Plattformen herzustellen. Es soll gezeigt werden, wie neue Infrastruktur automatisiert und Cloud-übergreifend integriert werden kann, so dass sie anschließend für alle berechtigten Teilnehmer erreichbar ist. Dies soll möglichst mit freier, offener Software und RFC-konformen Protokollen geschehen.\\
Interessant ist diese Lösung für Unternehmen, welche die Lizenzkosten für proprietäre Lösungen sparen wollen oder bevorzugt auf offene Systeme und Standards setzen, welche eine hohe Interoperabilität zu anderen (offenen) Systemen versprechen.

\section{Inhalt}
Es sollen verschiedene Use-Cases erarbeitet werden, die im Kontext einer Cloud-Vernetzung geeignet erscheinen, um verschiedene Netzwerkdienste (redundant) anzubieten. Grundlegend wird davon ausgegangen, dass ein Kunde Netzwerkdienste bereits \gls{on-premises} nutzt und diese zu AWS und Azure hin erweitern möchte, um eine Hochverfügbarkeit bzw. einen Lastenausgleich zu erreichen.\\
Im ersten Schritt muss dafür ein geeignetes Design für die Vernetzung zwischen den verschiedenen Standorten gefunden werden. Dieses Design soll mit Hilfe geeigneter technischer Werkzeuge umgesetzt werden und dient im Anschluss als Grundlage für die Abbildung der zuvor definierten Use-Cases.\\
Diese technisch abgebildeten Use-Cases sind im Einzelnen als Proof-of-Concept (PoC) anzusehen und sollen abschließend in Bezug auf im Voraus formulierte, in der Praxis übliche Anforderungen und Kriterien analysiert und bewertet werden. Es ist davon auszugehen, dass im Rahmen der Umsetzung der Autor mit diversen technischen Problemen konfrontiert sein wird. Die Analyse und Diskussion dieser Problemstellungen soll zu geeigneten Lösungsansätzen führen.

\textbf{\underline{Herausgestellte Aspekte der Bachelorarbeit}}
\begin{itemize}
    \item Kein \textbf{feste} Bindung an einen Cloud-Provider (\glqq Vendor Lock-In\grqq{}), da das Netzwerk über mehrere Cloud-Plattformen gespannt wird.
    \item Möglichkeit der Hochverfügbarkeit und des Lastenausgleichs für Netzwerkdienste über mehrere Cloud-Plattformen hinweg
    \item Projekte oder Dienste, die eine \textit{bestimmte} Cloud-Plattform erfordern, können für weitere (Cloud-)Plattformen verfügbar gemacht werden
    \item Latenz- oder Bandbreitenanforderungen können durch eine Hybrid-Cloud-Strategie u.U. besser eingehalten werden
    \item Neue Cloud-Netzwerke können dynamisch und automatisiert aufgebaut werden und stehen im Anschluss für alle berechtigten Teilnehmer zur Verfügung
\end{itemize}

\textbf{\underline{Beleuchtete Fragestellungen}}
\begin{itemize}
    \item Mit Hilfe welcher Technologien und Systemkomponenten lässt sich so eine Lösung aufbauen?
    \item Welche Schnittstellen werden bei den jeweiligen Cloud-Plattformen angeboten, um eine automatisierte Vernetzung zu bewerkstelligen?
    \item Welche Werkzeuge können mit diesen Schnittstellen genutzt werden?
    \item Welche Netzwerk-Topologie bieten sich an, um mehrere Cloud-Plattformen miteinander zu verbinden?
    \item Auf welche Netzwerk-Protokolle kann zurückgegriffen werden?
    \item Wie kann eine hohe Sicherheit im Netzwerk zwischen den Plattformen gewährleistet werden, um fremde Zugriffe zu verhindern?
    \item Sind Bandbreiten- und Latenzanforderungen in typischen Szenarien erfüllbar? Wie kann u.U. ein Lastenausgleich herbeigeführt werden?
\end{itemize}

\textbf{\underline{Abgrenzungen}}\label{abgrenzung}

\begin{itemize}
\item Es wird herausgearbeitet, wie eine Ende-zu-Ende-Konnektivität zwischen verschiedenen Cloud-Plattform ermöglicht werden kann. Dies soll mit privaten RFC 1918-Adressen geschehen und dies automatisiert evtl. unter Zuhilfenahme eines IP Adressmanagements (IPAM).
\item IPv6-Adressierung wird in dieser Arbeit nicht berücksichtigt: IPv6-Unterstützung ist auf den Cloud-Plattformen teilweise eingeschränkt und Kunden nutzen meist noch IPv4 für interne Adressierungen\cite{azureipv6_2020}.
\item Broadcast- und Multicast-Anwendungen werden in den Use-Cases nicht berücksichtigt. Auch hier gibt es nur eingeschränkte Unterstützung seitens der Cloud-Provider.
\item Typische \gls{on-premises} (Private) Cloud-Lösungen wie OpenStack oder OpenShift werden auf Grund ihrer hohen Komplexität in der Bachelor-Arbeit nicht berücksichtigt. Solche Plattformen sollen in der Bachelor-Arbeit durch eine Abstraktion dargestellt werden.
\item Weitere Cloud-Anbieter wie Google oder IBM werden nicht berücksichtigt. Das Hauptaugenmerk liegt auf AWS, Azure und der Integration einer Private Cloud.
\item Verschlüsselungsparameter zur Absicherung von Verbindungen werden nicht tiefergehend beleuchtet, sondern ein \textit{vorgegebener} Verschlüsselungsgrad der Cloud-Provider als ausreichend angenommen.
\item Es werden vereinzelte Bandbreitenmessungen zwischen den Standorten erwogen und auf Plausibilität geprüft. Sie sind jedoch nicht Fokus dieser Arbeit, da zu viele Faktoren einen negativen Einfluss darauf haben können. Es werden Überlegungen zur Optimierung im Ausblick (s. \ref{ausblick}) angestellt.
\item Entgegen des initialen Proposals zielt die Arbeit nicht mehr auf kleine und mittelständische Unternehmen, sondern auf kleine bis mittelgroße \textbf{Skalierungen} ab. Es hat sich während der praktischen Bearbeitung der Use-Cases herausgestellt, dass die genutzten Technologien so robust sind, dass ein Einsatz auch im \glqq größeren \textbf{technischen} Rahmen\grqq{} machbar ist. Aus technischer Sicht stellt sich nicht die Frage, wie \glqq groß\grqq{} ein Kunde ist, sondern welche Anforderungen (Latenz, Bandbreite, Uptime, etc.) in der Praxis tatsächlich vorherrschen. Es wird daher zum Ende der Arbeit noch ein Ausblick gegeben, wie beliebig große Skalierungen mit schärferen Performance-Kriterien, neben den erarbeiteten Lösungsvorschlägen, auch bedient werden können.
\end{itemize}

\iffalse
Serifen Schrit für Programmnamen?
Teilweise gekürzt mit [...] oder Funktionsnamen der Einfachheit umbenannt oder vereinfacht dargestellt
Todo: RFC 5737 in Einleitung (Documentation IPs)
Getestet mit Terraform Version...
Abkürzungen AWS, VPC werden einmal erläutert, danach Schicht im Schacht
Rein technischer Natur, es wird nicht auf Kostenoptimierung eingangen -> dafür ist Cloud-Costs zu komplex
Abgrenzung: alle Public-IP und Private-IP beziehen sich auf IPv3!!!
Kommandos sind mit Dollar markiert. Sie werden genutzt, wenn ein Filterausdruck erkennbar sein soll, oftmals mit grep
Typische Schalter in dieser Arbeit:
-A n: Zeige auch die nächsten n Zeilen nach einem Treffer
-B n: Zeige auch die vorherigen n Zeilen vor einem Treffer
-o Zeige ausschließlich den Treffer, nicht die komplette Zeile, oftmals im Zusammenspiel mit -E
-E Suche mit Hilfe von regulären Ausdrücken (Regex)
-v ignoriere Zeilen, die das Pattern beinhalten (invertiere)
Linux-Grundlagen werden vorausgesetzt, iptables, cat, head, tail, 
Alle Zeichnungen wurden draw.io gemacht. Auch die Shapes entstammen draw.io
Monospace für Programmaufrufe
Unterstrichen für Dateinamen
Alle Codebeispiele finden sich im Github
\fi
