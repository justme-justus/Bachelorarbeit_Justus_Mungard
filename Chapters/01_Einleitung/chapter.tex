%SASE? https://en.wikipedia.org/wiki/Secure_Access_Service_Edge
%keine KMU => kleine und mittlere Skalierungen
\chapter{Einleitung}

Viele Kunden der NetUSE AG nehmen \textit{Public Cloud}-basierte Dienste in Anspruch, um ehemals hausinterne IT-Infrastruktur dorthin zu verlagern bzw. zu erweitern. Auf der technischen Ebene spricht dafür oftmals, dass passende Infrastruktur und Ressourcen für einen Dienst on-premise\cite{Karlstetter2017} nicht zur Verfügung stehen. \textit{Entscheider} sehen in der Cloud eine Möglichkeit der Kosteneinsparung zusammen mit einer besseren Aufschlüsselung, welche Kosten für den Betrieb eines Dienstes verursacht werden. Kosten bspw. für den Aufbau und Betrieb können sich in einer klassischen Infrastruktur über verschiedene Teams erstrecken. Das wären bspw. bei der NetUSE AG: Server-Einbau und -Installation (Team \glqq{Infrastruktur}\grqq{}), Netzwerkanbindung (Team \glqq{Netzwerk}\grqq{}), Pflege von Firewall-Regeln (Team \glqq{Security}\grqq{}).\\
In der Cloud werden diese Schritte zusammengefasst und per Knopfdruck (virtuelle) Maschinen und Infrastruktur bereitgestellt\cite{Karlstetter2017a}. Dies passiert in größeren Skalierungen automatisiert, z.B. Skript-gesteuert oder mit Hilfe von Automatisierungs-Frameworks wie Ansible oder Terraform, wobei Cloud-Plattformen die passenden Schnittstellen zur Verfügung stellen\cite{edelman2018}\cite{Brikman2019}.\\
Public Cloud-Provider bringen damit einen Paradigmenwechsel in die IT-Landschaft: Server, auf denen gewünschte Dienste installiert sind, sind nicht mehr vor Ort beim Kunden oder bei einem Managed Service Provider (MSP)\cite{Laimingas2017} angesiedelt. Typische Prozesse wie die Grundinstallation eines Betriebssystems erübrigen sich. Außerdem existieren viele fertige bzw. vorbereitete Lösungen und sind über einen Cloud-Marketplace erhältlich.\\
Ebenso gibt es in der Public Cloud keine klassische Netzwerk-Infrastruktur: Broadcast-fähige Layer-2-Domänen, welche ursprünglich notwendig waren, um lokale Netzwerkteilnehmer (ARP [IPv4] bzw. Neighbor Discovery [IPv6]) zu finden, werden nicht mehr benötigt: Die Cloud \textit{kennt} naturgemäß alle Teilnehmer und es ist nach Belieben möglich, Konnektivität zwischen diesen zu ermöglichen.\\
Netzwerke in der Cloud sind Software-Defined (SDN)\cite{Seidel2015}. Das hat zur Folge, dass gewohnte Werkzeuge eines Netzwerk-Ingenieurs wegfallen, während gleichzeitig neue dazu gekommen sind, um Netzwerke (wieder-)herzustellen.\\
Die NetUSE AG sieht zur Zeit zwei Public Cloud-Anbieter für ihr Geschäft im Fokus: Amazon Web Services (AWS) und Microsoft Azure. Weiterhin unterstützt die Firma Kunden beim Aufbau einer \textit{Private Cloud} mit Red Hat OpenShift. Unterhält ein Unternehmen sowohl eine Public als auch eine Private Cloud und will eine Brücke zwischen diesen schlagen, wird dies als \textit{Hybrid Cloud} bezeichnet.\\
Eine Vernetzung zwischen verschiedenen Clouds ist nicht trivial zu lösen, insofern diese Infrastruktur gegen das Internet isoliert werden soll.
Die Bachelorarbeit zielt darauf ab, wie ein möglichst generisches Netzwerk zwischen verschiedenen Cloud-Plattformen herzustellen ist. Dies soll automatisiert passieren, sodass eine IP-Konnektivität neuer Infrastruktur über Anbietergrenzen hinweg nach kurzer Zeit und ohne manuelle Interaktion gegeben ist. Die Konfigurationen sollen möglichst über die bereits verfügbaren Schnittstellen der Anbieter stattfinden. Sobald die Netzwerkumgebung zur Verfügung steht, soll anhand typischer Use-Cases in kleinen bis mittelgroßen Skalierungen gezeigt werden, wie typische (Server-)Dienste und \textit{Fail-Over Szenarien}\cite{DBG2011} in einem Cloud-Netzwerk abgebildet werden können.

\section{Ziel}

Es existieren bereits proprietäre Lösungen am Markt, um eine Vernetzung über Cloud-Anbieter hinweg zu ermöglichen. Sie fallen in die Kategorie \textit{Software-Defined Wide Area Network (SD-WAN)} und sind nicht interoperabel zu SD-WAN-Lösungen anderer Hersteller.\\
Ziel der Arbeit wird sein, ein möglichst herstellerunabhängiges Netzwerk, welches eine Ende-zu-Ende-Konnektivität ermöglicht, zwischen verschiedenen Cloud-Plattformen herzustellen. Es soll gezeigt werden, wie neue Infrastruktur automatisiert und Cloud-übergreifend integriert werden kann, so dass sie anschließend für alle berechtigten Teilnehmer erreichbar ist. Dies soll möglichst mit freier, offener Software und RFC-konformen Protokollen geschehen.\\
Interessant ist diese Lösung bspw. für Unternehmen, welche die Lizenzkosten für proprietäre Lösungen sparen wollen oder bevorzugt auf offene Systeme bzw. Standards setzen, welche eine hohe Interoperabilität zu anderen (offenen) Systemen versprechen.

\section{Inhalt}
%Es soll ein Katalog erstellt werden, welcher typische Anforderungen von kleinen und mittelständischen Kunden der NetUSE AG auflistet. Dieser umfasst vsl. Punkte der Skalierbarkeit, Orchestration, Performanz und Sicherheit hinsichtlich einer Cloud-Vernetzung.\\
%Da die NetUSE AG jahrelanger Partner des Netzwerk-Ausrüsters Cisco ist, soll untersucht werden, welche Lösungen in diesem Feld bereits von Cisco angeboten werden. Dabei wird der entworfene Anforderungskatalog zu Hilfe genommen.\\
%Aus diesem Erkenntnisgewinn soll ein Design für eine offene Lösung erarbeitet und in einem Proof-of-Concept manifestiert werden. Um eine Automatisierung zu erlangen, werden evtl. Programmierarbeiten erforderlich.\\
Es sollen verschiedene Use-Cases erarbeitet werden, die im Kontext einer Cloud-Vernetzung geeignet erscheinen, um verschiedene Netzwerkdienste (redundant) anzubieten. Grundlegend wird davon ausgegangen, dass ein Kunde Netzwerkdienste bereits on-premise nutzt und diese zu AWS und Azure hin erweitern möchte, um eine Hochverfügbarkeit bzw. einen Lastenausgleich zu erreichen.\\
Im ersten Schritt muss dafür ein geeignetes Design für die Vernetzung zwischen den verschiedenen Standorten gefunden werden. Dieses Design soll mit Hilfe geeigneter technischer Werkzeuge umgesetzt werden und dient im Anschluss als Grundlage für die Abbildung der zuvor definierten Use-Cases.\\
Diese technisch abgebildeten Use-Cases sind im Einzelnen als Proof-of-Concept (PoC) anzusehen und sollen abschließend in Bezug auf im Voraus formulierte, in der Praxis übliche Anforderungen und Kriterien analysiert und bewertet werden. Es ist davon auszugehen, dass im Rahmen der Umsetzung der Autor mit diversen technischen Problemen konfrontiert sein wird. Die Analyse und Diskussion dieser Problemstellungen soll zu geeigneten Lösungsansätzen führen.

\textbf{\underline{Herausgestellte Aspekte der Bachelorarbeit}}
\begin{itemize}
    \item Kein \textbf{feste} Bindung an einen Cloud-Provider (\glqq Vendor Lock-In\grqq{}), da das Netzwerk über mehrere Cloud-Plattformen gespannt wird.
    \item Möglichkeit der Hochverfügbarkeit und des Lastenausgleichs für Netzwerkdienste über mehrere Cloud-Plattformen hinweg
    \item Projekte oder Dienste, die eine \textit{bestimmte} Cloud-Plattform erfordern, können für weitere (Cloud-)Plattformen verfügbar gemacht werden
    \item Latenz- oder Bandbreitenanforderungen können durch eine Hybrid-Cloud-Strategie u.U. besser eingehalten werden
    \item Neue Cloud-Netzwerke können dynamisch und automatisiert aufgebaut werden und stehen im Anschluss für alle berechtigten Teilnehmer zur Verfügung
\end{itemize}

\textbf{\underline{Beleuchtete Fragestellungen}}
\begin{itemize}
    \item Mit Hilfe welcher Technologien und Systemkomponenten lässt sich so eine Lösung aufbauen?
    \item Welche Schnittstellen werden bei den jeweiligen Cloud-Plattformen angeboten, um eine automatisierte Vernetzung zu bewerkstelligen?
    \item Welche Werkzeuge können mit diesen Schnittstellen genutzt werden?
    \item Welche Netzwerk-Topologie bieten sich an, um mehrere Cloud-Plattformen miteinander zu verbinden?
    \item Auf welche Netzwerk-Protokolle kann zurückgegriffen werden?
    \item Wie kann eine hohe Sicherheit im Netzwerk zwischen den Plattformen gewährleistet werden, um fremde Zugriffe zu verhindern?
    \item Sind Bandbreiten- und Latenzanforderungen in typischen Szenarien erfüllbar? Wie kann u.U. ein Lastenausgleich herbeigeführt werden?
\end{itemize}

\textbf{\underline{Abgrenzungen}}

\begin{itemize}
%Nicht Overlay... Abstraktion, um per IPv4 eine Ende-zu-Ende-Konnektivität herzustellen
\item Es wird herausgearbeitet, wie eine Ende-zu-Ende-Konnektivität zwischen verschiedenen Cloud-Plattform ermöglicht werden kann. Dies soll mit privaten RFC 1918-Adressen geschehen und dies automatisiert evtl. unter Zuhilfenahme eines IP Adressmanagements (IPAM).
\item IPv6-Adressierung wird in dieser Arbeit nicht berücksichtigt: IPv6-Unterstützung ist auf den Cloud-Plattformen teilweise eingeschränkt und Kunden nutzen meist noch IPv4 für interne Adressierungen\cite{azureipv6_2020}.
\item Broadcast- und Multicast-Anwendungen werden in den Use-Cases nicht berücksichtigt. Auch hier gibt es nur eingeschränkte Unterstützung seitens der Cloud-Provider.
%\item Hochverfügbarkeit von Internetdiensten (bspw. ein MySQL-Cluster) über mehrere Cloud-Plattformen hinweg ist nicht Teil der Bachelor-Arbeit.
\item Typische On-Premise (Private) Cloud-Lösungen wie OpenStack oder OpenShift werden auf Grund ihrer hohen Komplexität in der Bachelor-Arbeit nicht berücksichtigt. Solche Plattformen sollen in der Bachelor-Arbeit durch eine Abstraktion dargestellt werden.
\item Weitere Cloud-Anbieter wie Google oder IBM werden nicht berücksichtigt. Das Hauptaugenmerk liegt auf AWS, Azure und der Integration einer Private Cloud.
\item Verschlüsselungsparameter zur Absicherung von Verbindungen werden nicht tiefergehend beleuchtet, sondern ein \textit{vorgegebener} Verschlüsselungsgrad der Cloud-Provider als ausreichend angenommen.
\item Es werden vereinzelte Bandbreitenmessungen zwischen den Standorten erwogen und auf Plausibilität geprüft. Sie sind jedoch nicht Fokus dieser Arbeit, da zu viele Faktoren einen negativen Einfluss darauf haben können. Es werden Überlegungen zur Optimierung im Ausblick (s. \ref{ausblick}) angestellt.
\item Entgegen des initialen Proposals zielt die Arbeit nicht mehr auf kleine und mittelständische Unternehmen, sondern auf kleine bis mittelgroße \textbf{Skalierungen} ab. Es hat sich während der praktischen Bearbeitung der Use-Cases herausgestellt, dass die genutzten Technologien so robust sind, dass ein Einsatz auch im \glqq größeren \textbf{technischen} Rahmen\grqq{} machbar ist. Aus technischer Sicht stellt sich nicht die Frage, wie \glqq groß\grqq{} ein Kunde ist, sondern welche Anforderungen (Latenz, Bandbreite, Uptime, etc.) in der Praxis tatsächlich vorherrschen. Es wird daher zum Ende der Arbeit noch ein Ausblick gegeben, wie beliebig große Skalierungen mit schärferen Performance-Kriterien, neben den erarbeiteten Lösungsvorschlägen, auch bedient werden können.
%Kein Best Practice Security, DH etc...

%BFD, SLA, QoS, VNET / VPC Peering / Microsoft SDWAN / TG?

\end{itemize}

\iffalse
Serifen Schrit für Programmnamen?
Teilweise gekürzt mit [...] oder Funktionsnamen der Einfachheit umbenannt oder vereinfacht dargestellt
Todo: RFC 5737 in Einleitung (Documentation IPs)
Getestet mit Terraform Version...
Abkürzungen AWS, VPC werden einmal erläutert, danach Schicht im Schacht
Rein technischer Natur, es wird nicht auf Kostenoptimierung eingangen -> dafür ist Cloud-Costs zu komplex
Abgrenzung: alle Public-IP und Private-IP beziehen sich auf IPv3!!!
Kommandos sind mit Dollar markiert. Sie werden genutzt, wenn ein Filterausdruck erkennbar sein soll, oftmals mit grep
Typische Schalter in dieser Arbeit:
-A n: Zeige auch die nächsten n Zeilen nach einem Treffer
-B n: Zeige auch die vorherigen n Zeilen vor einem Treffer
-o Zeige ausschließlich den Treffer, nicht die komplette Zeile, oftmals im Zusammenspiel mit -E
-E Suche mit Hilfe von regulären Ausdrücken (Regex)
-v ignoriere Zeilen, die das Pattern beinhalten (invertiere)
Linux-Grundlagen werden vorausgesetzt, iptables, cat, head, tail, 
Alle Zeichnungen wurden draw.io gemacht. Auch die Shapes entstammen draw.io
Monospace für Programmaufrufe
Unterstrichen für Dateinamen
Alle Codebeispiele finden sich im Github
\fi